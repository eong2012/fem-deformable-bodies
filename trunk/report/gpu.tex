An interesting extension to the implementation would be to execute some tasks in parallel on the GPU. There are sections in the implementation that could probably be well suited for parallelization, such as the conjugate gradient solver. In order to utilize the parallel properties of the GPU the problem must be rewritten. Bolz et al. \cite{gpu} suggests a method for implementing the conjugate gradient method on the GPU that consists of two tasks, computing the sparse matrix-vector multiplication and a vector inner product.

This method makes use of several textures, two containing the non-zero elements of the matrix $\mathbf{A}$ used in the conjugate gradient method, others containing various pointers to indices that makes it possible to know which elements are used . Implementing this method 
